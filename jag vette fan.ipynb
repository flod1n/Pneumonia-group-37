{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import flatten, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,f1_score\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 7\n",
    "SHUFFLE = True\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 5\n",
    "\n",
    "CUDA = True\n",
    "if CUDA and torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else: device = \"cpu\"\n",
    "print(\"device is:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_val_loss = 1000\n",
    "    best_model = model\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # labels = labels.unsqueeze(-1) # -1 stands for last here equivalent to 1\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss.to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        writer.add_scalar(\"loss/train\", train_loss, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "    return best_model\n",
    "\n",
    "def labelcounter(dataloader):\n",
    "    pos,neg = 0,0\n",
    "    for pic, label in dataloader:\n",
    "        label_values = label.tolist()\n",
    "        for label_value in label_values:\n",
    "            if label_value == 0:\n",
    "                neg += 1\n",
    "            else:\n",
    "                pos += 1\n",
    "    return pos,neg\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "        # Calculate additional metrics\n",
    "        precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "        recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "        f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "    return test_loss, accuracy, precision, recall, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = r\"C:\\Users\\ludvi\\Documents\\Code\\tjena\\chest_xray\\train\"\n",
    "VAL_DATA_DIR = r\"C:\\Users\\ludvi\\Documents\\Code\\tjena\\chest_xray\\val\"\n",
    "TEST_DATA_DIR = r\"C:\\Users\\ludvi\\Documents\\Code\\tjena\\chest_xray\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 5216\n",
      "val set size: 16\n",
      "test set size: 624\n"
     ]
    }
   ],
   "source": [
    "# transform = v2.Compose([\n",
    "#         v2.Resize(size=(224,224)),\n",
    "#         v2.RandomHorizontalFlip(p=0.5),\n",
    "#         v2.ToTensor(),\n",
    "#         v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "#         v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                             std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "# Load dataset\n",
    "train_set = datasets.ImageFolder(root=TRAIN_DATA_DIR, transform=transform)\n",
    "val_set = datasets.ImageFolder(root=VAL_DATA_DIR,transform=transform)\n",
    "test_set = datasets.ImageFolder(root=TEST_DATA_DIR,transform=transform)\n",
    "\n",
    "# Create data loaders for train, validation, and test sets\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# transToPIL = v2.ToPILImage()\n",
    "# img = transToPIL(train_set[0][0])\n",
    "# img.show()\n",
    "\n",
    "print(\"train set size:\",len(train_set))\n",
    "print(\"val set size:\",len(val_set))\n",
    "print(\"test set size:\",len(test_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_pos,train_neg \u001b[38;5;241m=\u001b[39m \u001b[43mlabelcounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m val_pos,val_neg \u001b[38;5;241m=\u001b[39m labelcounter(val_loader)\n\u001b[0;32m      3\u001b[0m test_pos,test_neg \u001b[38;5;241m=\u001b[39m labelcounter(test_loader)\n",
      "Cell \u001b[1;32mIn[4], line 120\u001b[0m, in \u001b[0;36mlabelcounter\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlabelcounter\u001b[39m(dataloader):\n\u001b[0;32m    119\u001b[0m     pos,neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_values\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\PIL\\Image.py:1087\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     dither \u001b[38;5;241m=\u001b[39m Dither\u001b[38;5;241m.\u001b[39mFLOYDSTEINBERG\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1087\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m         \u001b[38;5;66;03m# normalize source image and try again\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_pos,train_neg = labelcounter(train_loader)\n",
    "val_pos,val_neg = labelcounter(val_loader)\n",
    "test_pos,test_neg = labelcounter(test_loader)\n",
    "\n",
    "species = ('train', 'val', 'test')\n",
    "balance = {\n",
    "    'positive': np.array([train_pos, val_pos, test_pos]),\n",
    "    'negative': np.array([train_neg, val_neg, test_neg]),\n",
    "}\n",
    "width = 0.7  # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(3)\n",
    "\n",
    "for positive, negative in balance.items():\n",
    "    p = ax.bar(species, negative, width, label=positive, bottom=bottom)\n",
    "    bottom += negative\n",
    "\n",
    "    ax.bar_label(p, label_type='center')\n",
    "\n",
    "ax.set_title('Dataset balance')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_resnet(nn.Module):\n",
    "    def init(self):\n",
    "        super().init()\n",
    "        self.resnet = torchvision.models.resnet101(pretrained=True)\n",
    "        modules = list(self.resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.dem_red1 = nn.Conv2d(2048, 1024, kernel_size=1, padding=0)\n",
    "        self.dem_red2 = nn.Conv2d(1024, 512, kernel_size=1, padding=0)\n",
    "        self.fc1 = nn.Linear(5127*7,1000)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,1)\n",
    "        self.myparameters = nn.ParamersList(self.resnet, self.dem_red1,self.dem_red2,self.fc1,self.fc2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dem_red1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dem_red2(x)\n",
    "        x = self.act(x)\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wtf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.RELU = nn.ReLU()\n",
    "        self.Tan = nn.Tanh()\n",
    "\n",
    "        self.densenet = torchvision.models.densenet.DenseNet()\n",
    "        \n",
    "        # input: 32x32x1\n",
    "        self.c1 = nn.Conv2d(1, 3, kernel_size=3, padding=1) # output: 32x32x3 SAME\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 16x16x3 \n",
    "        self.c2 = nn.Conv2d(3, 6, kernel_size=3, padding=1) # output: 16x16x6 SAME\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 8x8x6 \n",
    "        self.c3 = nn.Conv2d(6, 12, kernel_size=3, padding=1) # output: 8x8x12 SAME\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=8*8*12, out_features=60) \n",
    "\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Conv Layer 1\n",
    "        x = self.c1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool1(x)\n",
    "        #Conv Layer 2        \n",
    "        x = self.c2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool2(x)\n",
    "        #Conv Layer 3\n",
    "        x = self.c3(x)\n",
    "        x = self.act(x)\n",
    "        #Flattening\n",
    "        x = torch.flatten(x, 1)\n",
    "        #FC Layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        #FC Layer 2\n",
    "        x = self.fc2(x)    \n",
    "        #Softmax\n",
    "        out = self.logSoftmax(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearning(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(TransferLearning, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.my_new_layers = nn.Sequential(nn.Linear(1000, 100),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(100, 0)) # Binary classification?\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.my_new_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/746 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([7])) that is different to the input size (torch.Size([7, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# criterion = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean').to(device)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m trained_model1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m test_loss, accuracy, precision, recall, f1, conf_matrix \u001b[38;5;241m=\u001b[39m test_model(trained_model1, test_loader, criterion)\n",
      "Cell \u001b[1;32mIn[4], line 86\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[0;32m     84\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# labels = labels.unsqueeze(-1) # -1 stands for last here equivalent to 1\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     88\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ludvi\\anaconda3\\envs\\Jaha\\Lib\\site-packages\\torch\\nn\\functional.py:3145\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3143\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3148\u001b[0m     )\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([7])) that is different to the input size (torch.Size([7, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "densenet = TransferLearning(torchvision.models.densenet.densenet121()).to(device)\n",
    "# print(densenet)\n",
    "optimizer = torch.optim.Adam(params=densenet.parameters(),lr=0.0001)\n",
    "# criterion = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean').to(device)\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "trained_model1 = train_model(densenet,criterion,optimizer,train_loader,val_loader,num_epochs=EPOCHS)\n",
    "# Test the model\n",
    "test_loss, accuracy, precision, recall, f1, conf_matrix = test_model(trained_model1, test_loader, criterion)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\",f1)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix, classes=['Negative', 'Positive'], normalize=True)\n",
    "plt.show()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.25\n",
      "Precision: 0.8509090087573731\n",
      "Recall: 0.8125\n",
      "F1-Score: 0.7945215526079207\n",
      "Test Loss: 0.0937, Test Accuracy: 81.25%\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAJhCAYAAAC0OPN7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABh40lEQVR4nO3dd3hU1dr+8XvSC0kglCRIhAgB6V0IKr0YejkUiQhKUWknAsIRBOKrEEClqqiIFAFBpYigCEgTASmCVOlI0MSglJAQUuf3B2Z+DhMkgQzJHr8frn1dZu81a57JefPy5GbttU1ms9ksAAAAwOCc8rsAAAAAIC/Q2AIAAMAh0NgCAADAIdDYAgAAwCHQ2AIAAMAh0NgCAADAIdDYAgAAwCHQ2AIAAMAh0NgCAADAIdDYAsgzBw8e1DPPPKOQkBB5eHioUKFCqlWrlqZMmaJLly7Z9b3379+vRo0ayc/PTyaTSdOnT8/z9zCZTIqKisrzeQuSiRMnatWqVbl6zfz582UymXTu3Dm71AQAOWXikboA8sKcOXM0cOBAVahQQQMHDlSlSpWUlpamvXv3as6cOapevbpWrlxpt/evWbOmkpKSNGPGDBUpUkRlypRRYGBgnr7Hrl27VKpUKZUqVSpP5y1IChUqpP/85z+aP39+jl9z8eJFnT59WjVr1pS7u7v9igOAO6CxBXDPdu7cqccff1wtWrTQqlWrbJqb1NRUrVu3Tu3bt7dbDa6ururfv7/effddu73Hv0FuGtvk5GR5eHjIZDLZvzAAyAGWIgC4ZxMnTpTJZNIHH3yQbWLn5uZm1dRmZmZqypQpevjhh+Xu7q4SJUro6aef1oULF6xe17hxY1WpUkV79uzR448/Li8vLz300EOaNGmSMjMzJf3/fwZPT0/X7NmzZTKZLI1WVFRUtk1Xdv90vmnTJjVu3FhFixaVp6enHnzwQXXp0kXXr1+3jMluKcLhw4fVoUMHFSlSRB4eHqpRo4YWLFhgNWbLli0ymUz65JNPNGbMGJUsWVK+vr5q3ry5jh8/fsfvb9bnOHjwoLp27So/Pz/5+/tr2LBhSk9P1/Hjx/XEE0/Ix8dHZcqU0ZQpU6xef+PGDQ0fPlw1atSwvDYsLExffPGF1TiTyaSkpCQtWLDA8n1s3Lix1fds/fr1evbZZ1W8eHF5eXkpJSXF5vt58uRJ+fr6qmvXrlbzb9q0Sc7Ozho7duwdPzMA3A0aWwD3JCMjQ5s2bVLt2rUVHByco9e88MILGjVqlFq0aKHVq1frtdde07p169SgQQP98ccfVmPj4uIUERGhp556SqtXr1Z4eLhefvllLVq0SJLUpk0b7dy5U5L0n//8Rzt37rR8nVPnzp1TmzZt5Obmpo8++kjr1q3TpEmT5O3trdTU1Nu+7vjx42rQoIGOHDmimTNnasWKFapUqZL69Olj01xK0ujRo/XLL7/oww8/1AcffKCTJ0+qXbt2ysjIyFGd3bp1U/Xq1bV8+XL1799f06ZN04svvqiOHTuqTZs2WrlypZo2bapRo0ZpxYoVltelpKTo0qVLGjFihFatWqVPPvlEjz32mDp37qyFCxdaxu3cuVOenp5q3bq15ft4awL+7LPPytXVVR9//LE+//xzubq62tQZGhqqOXPm6PPPP9fMmTMl3fzfsWfPnnr88ccdfp0ygHxkBoB7EBcXZ5Zk7tGjR47GHzt2zCzJPHDgQKvzP/zwg1mSefTo0ZZzjRo1Mksy//DDD1ZjK1WqZG7VqpXVOUnmQYMGWZ0bP368Obv/Nzdv3jyzJPPZs2fNZrPZ/Pnnn5slmQ8cOPCPtUsyjx8/3vJ1jx49zO7u7ubz589bjQsPDzd7eXmZr1y5YjabzebNmzebJZlbt25tNe7TTz81SzLv3LnzH98363O89dZbVudr1KhhlmResWKF5VxaWpq5ePHi5s6dO992vvT0dHNaWpq5b9++5po1a1pd8/b2Nvfu3dvmNVnfs6effvq217K+n1leeOEFs5ubm3nnzp3mpk2bmkuUKGH+7bff/vGzAsC9ILEFcF9t3rxZktSnTx+r84888ogqVqyob7/91up8YGCgHnnkEatz1apV0y+//JJnNdWoUUNubm4aMGCAFixYoDNnzuTodZs2bVKzZs1skuo+ffro+vXrNsnxrWuMq1WrJkk5/ixt27a1+rpixYoymUwKDw+3nHNxcVG5cuVs5vzss8/06KOPqlChQnJxcZGrq6vmzp2rY8eO5ei9s3Tp0iXHY6dNm6bKlSurSZMm2rJlixYtWqSgoKBcvR8A5AaNLYB7UqxYMXl5eens2bM5Gv/nn39KUrYNTsmSJS3XsxQtWtRmnLu7u5KTk++i2uyVLVtWGzduVIkSJTRo0CCVLVtWZcuW1YwZM/7xdX/++edtP0fW9b+79bNkrUfO6Wfx9/e3+trNzU1eXl7y8PCwOX/jxg3L1ytWrFC3bt30wAMPaNGiRdq5c6f27NmjZ5991mpcTuSmMXV3d1fPnj1148YN1ahRQy1atMjVewFAbtHYArgnzs7Oatasmfbt22dz81d2spq72NhYm2u//fabihUrlme1ZTV8KSkpVudvXccrSY8//ri+/PJLXb16Vbt27VJYWJgiIyO1dOnS285ftGjR234OSXn6We7FokWLFBISomXLlqljx46qX7++6tSpY/N9yYnc7IBw+PBhjRs3TnXr1tWPP/6oqVOn5vr9ACA3aGwB3LOXX35ZZrNZ/fv3z/Zmq7S0NH355ZeSpKZNm0qS5eavLHv27NGxY8fUrFmzPKurTJkykm4+OOLvsmrJjrOzs+rVq6d33nlHkvTjjz/edmyzZs20adMmSyObZeHChfLy8lL9+vXvsvK8ZTKZ5ObmZtWUxsXF2eyKIOVdGp6UlKSuXbuqTJky2rx5swYPHqz//e9/+uGHH+55bgC4HZf8LgCA8YWFhWn27NkaOHCgateurRdeeEGVK1dWWlqa9u/frw8++EBVqlRRu3btVKFCBQ0YMECzZs2Sk5OTwsPDde7cOY0dO1bBwcF68cUX86yu1q1by9/fX3379tX//d//ycXFRfPnz1dMTIzVuPfee0+bNm1SmzZt9OCDD+rGjRv66KOPJEnNmze/7fzjx4/XmjVr1KRJE40bN07+/v5avHix1q5dqylTpsjPzy/PPsu9aNu2rVasWKGBAwfqP//5j2JiYvTaa68pKChIJ0+etBpbtWpVbdmyRV9++aWCgoLk4+OjChUq5Po9n3/+eZ0/f167d++Wt7e33nrrLe3cuVM9evTQ/v37Vbhw4Tz6dADw/9HYAsgT/fv31yOPPKJp06Zp8uTJiouLk6urq8qXL6+ePXtq8ODBlrGzZ89W2bJlNXfuXL3zzjvy8/PTE088oejo6GzX1N4tX19frVu3TpGRkXrqqadUuHBh9evXT+Hh4erXr59lXI0aNbR+/XqNHz9ecXFxKlSokKpUqaLVq1erZcuWt52/QoUK2rFjh0aPHq1BgwYpOTlZFStW1Lx582xujstPzzzzjOLj4/Xee+/po48+0kMPPaT//e9/unDhgl599VWrsTNmzNCgQYPUo0cPXb9+XY0aNdKWLVty9X4ffvihFi1apHnz5qly5cqSbq77XbZsmWrVqqVnnnnGrk+hA/DvxZPHAAAA4BBYYwsAAACHQGMLAAAAh0BjCwAAAIdAYwsAAACHQGMLAAAAh0BjCwAAAIfAPrYFUGZmpn777Tf5+Pjk6vGVAAAg75nNZl27dk0lS5aUk1PByARv3LiR7ZMe85Kbm5vl0eRGQWNbAP32228KDg7O7zIAAMDfxMTEqFSpUvldhm7cuCFPn6JS+nW7vk9gYKDOnj1rqOaWxrYA8vHxkSQt2LhfXt4++VwNgHvh7MS/ugBGdz3xmp5qVsPy93N+S01NldKvy71Sb8nZzT5vkpGquKMLlJqaSmOLe5O1/MDL20dehQrGDxGAu+NCYws4jAK3PNDFQyY7NbZmU8FYcpFbxqwaAAAAuAWJLQAAgBGZJNkrRS5g4XRO0dgCAAAYkcnp5mGvuQ3ImFUDAAAAtyCxBQAAMCKTyY5LEYy5FoHEFgAAAA6BxBYAAMCIWGNrw5hVAwAAALcgsQUAADAi1tjaILEFAACAQyCxBQAAMCQ7rrE1aPZpzKoBAACAW5DYAgAAGBFrbG2Q2AIAAMAhkNgCAAAYEfvY2jBm1QAAAMAtSGwBAACMiDW2NkhsAQAA4BBIbAEAAIyINbY2jFk1AAAAcAsSWwAAACNija0NGlsAAAAjYimCDWNWDQAAANyCxBYAAMCITCY7JrbGXIpAYgsAAACHQGILAABgRE6mm4e95jYgElsAAAA4BBJbAAAAI2JXBBvGrBoAAAC4BYktAACAEfGABhsktgAAAHAIJLYAAABGxBpbG8asGgAAALgFiS0AAIARscbWBoktAAAAHAKJLQAAgBGxxtaGMasGAAAAbkFiCwAAYESssbVBYgsAAACHQGILAABgRKyxtUFjCwAAYEQsRbBhzHYcAAAABcLs2bNVrVo1+fr6ytfXV2FhYfr6668t1/v06SOTyWR11K9f32qOlJQUDRkyRMWKFZO3t7fat2+vCxcu5LoWGlsAAABDcvr/yxHy+shFi1iqVClNmjRJe/fu1d69e9W0aVN16NBBR44csYx54oknFBsbazm++uorqzkiIyO1cuVKLV26VNu3b1diYqLatm2rjIyMXH1HWIoAAACAu9auXTurrydMmKDZs2dr165dqly5siTJ3d1dgYGB2b7+6tWrmjt3rj7++GM1b95ckrRo0SIFBwdr48aNatWqVY5rIbEFAAAwoqw1tvY6JCUkJFgdKSkp/1hSRkaGli5dqqSkJIWFhVnOb9myRSVKlFD58uXVv39/xcfHW67t27dPaWlpatmypeVcyZIlVaVKFe3YsSNX3xIaWwAAAGQrODhYfn5+liM6OjrbcYcOHVKhQoXk7u6u559/XitXrlSlSpUkSeHh4Vq8eLE2bdqkt956S3v27FHTpk0tTXJcXJzc3NxUpEgRqzkDAgIUFxeXq3pZigAAAGBEJpMdt/u6mdjGxMTI19fXctrd3T3b4RUqVNCBAwd05coVLV++XL1799bWrVtVqVIlde/e3TKuSpUqqlOnjkqXLq21a9eqc+fOty3BbDbLlMvdGUhsAQAAkK2snQ6yjts1tm5ubipXrpzq1Kmj6OhoVa9eXTNmzMh2bFBQkEqXLq2TJ09KkgIDA5WamqrLly9bjYuPj1dAQECu6qWxBQAAMCJ77YiQBw9+MJvNt12P++effyomJkZBQUGSpNq1a8vV1VUbNmywjImNjdXhw4fVoEGDXL0vSxEAAABw10aPHq3w8HAFBwfr2rVrWrp0qbZs2aJ169YpMTFRUVFR6tKli4KCgnTu3DmNHj1axYoVU6dOnSRJfn5+6tu3r4YPH66iRYvK399fI0aMUNWqVS27JOQUjS0AAIARFZAnj/3+++/q1auXYmNj5efnp2rVqmndunVq0aKFkpOTdejQIS1cuFBXrlxRUFCQmjRpomXLlsnHx8cyx7Rp0+Ti4qJu3bopOTlZzZo10/z58+Xs7Jy7ss1mszlXr4DdJSQkyM/PT5/tPCWvQj53fgGAAsvFyZiPpQTw/yUlXlPnemV19epVqxup8ktWn+D+xFsyuXra5T3MaclKWTe8wHzmnCKxBQAAMKI8WAv7j3MbkDGrBgAAAG5BYgsAAGBEBWSNbUFCYgsAAACHQGILAABgRKyxtWHMqgEAAIBbkNgCAAAYEWtsbdDYAgAAGJDJZJKJxtYKSxEAAADgEEhsAQAADIjE1haJLQAAABwCiS0AAIARmf467DW3AZHYAgAAwCGQ2AIAABgQa2xtkdgCAADAIZDYAgAAGBCJrS0SWwAAADgEElsAAAADIrG1RWILAAAAh0BiCwAAYEAktrZIbAEAAOAQSGwBAACMiCeP2SCxBQAAgEMgsQUAADAg1tjaorEFAAAwIJNJdmxs7TOtvbEUAQAAAA6BxBYAAMCATLLjUgSDRrYktgAAAHAIJLYAAAAGxM1jtkhsAQAA4BBIbAEAAIyIBzTYILEFAACAQyCxBQAAMCI7rrE1s8YWAAAAyD8ktgAAAAZkz10R7Lc/rn2R2AIAAMAhkNgCAAAYEImtLRJbAAAAOAQSWwAAACNiH1sbJLYAAABwCCS2AAAABsQaW1sktgAAAHAIJLYAAAAGRGJri8YWAADAgGhsbbEUAQAAAA6BxBYAAMCASGxtkdgCAADAIZDYAgAAGBEPaLBBYgsAAACHQGILAABgQKyxtUViCwAAAIdAYgsAAGBAJLa2SGwBAABw12bPnq1q1arJ19dXvr6+CgsL09dff225bjabFRUVpZIlS8rT01ONGzfWkSNHrOZISUnRkCFDVKxYMXl7e6t9+/a6cOFCrmuhsQUAADCgrMTWXkdOlSpVSpMmTdLevXu1d+9eNW3aVB06dLA0r1OmTNHUqVP19ttva8+ePQoMDFSLFi107do1yxyRkZFauXKlli5dqu3btysxMVFt27ZVRkZGrr4nNLYAAAC4a+3atVPr1q1Vvnx5lS9fXhMmTFChQoW0a9cumc1mTZ8+XWPGjFHnzp1VpUoVLViwQNevX9eSJUskSVevXtXcuXP11ltvqXnz5qpZs6YWLVqkQ4cOaePGjbmqhcYWAADAiEx2PiQlJCRYHSkpKf9YUkZGhpYuXaqkpCSFhYXp7NmziouLU8uWLS1j3N3d1ahRI+3YsUOStG/fPqWlpVmNKVmypKpUqWIZk1M0tgAAAMhWcHCw/Pz8LEd0dHS24w4dOqRChQrJ3d1dzz//vFauXKlKlSopLi5OkhQQEGA1PiAgwHItLi5Obm5uKlKkyG3H5BS7IgB55PDenVo+/x2dOnpQly7+rlemz1NYs9aW699vXKt1ny3UqaMHlXDlkmZ+9q3KPlzFao7YmHOa+2aUjuzfrbTUFNV+tKmef3mCihQrcb8/DvCvdWjvTn320Ts6efQnXbr4u8bPnK8Gf/tZ3r5hjb76dKFO/vWz/O7n36psxapWc7zUp6MO7rFOmhqFd9ToNz+4L58B/w73Y1eEmJgY+fr6Ws67u7tnO75ChQo6cOCArly5ouXLl6t3797aunWrzXxZzGbzHWvPyZhbkdgCeeRG8nWFlK+s50dn/9tsSvJ1VazxiPpEjsn+9deT9MqAbpLJpOgPP9ebC79Uelqq/m9IL2VmZtqzdAB/cyP5uh6qUFmDxmT/s3wj+boq1XxEz774yj/OE/6fXvpkyyHL8d/xb9qjXMCusnY6yDpu19i6ubmpXLlyqlOnjqKjo1W9enXNmDFDgYGBkmSTvMbHx1tS3MDAQKWmpury5cu3HZNTJLZAHqnzeDPVebzZba83bddVkvT7r+ezvX70wB7F/xajWZ99K69CPpKkyNdmqMdjFfTTD9+pZlijvC8agI26jzdT3X/4WW7evpskKe42P8tZ3D085V88d38pA7lRkPexNZvNSklJUUhIiAIDA7VhwwbVrFlTkpSamqqtW7dq8uTJkqTatWvL1dVVGzZsULduN3++YmNjdfjwYU2ZMiVX70tjCxQQaakpkskkVzc3yzk3d3c5OTnp6P7dNLaAwWxeu1yb1nyuwkWLq+7jTfXUwJfk5V0ov8sC8tzo0aMVHh6u4OBgXbt2TUuXLtWWLVu0bt06mUwmRUZGauLEiQoNDVVoaKgmTpwoLy8v9ezZU5Lk5+envn37avjw4SpatKj8/f01YsQIVa1aVc2bN89VLTS2d1CmTBlFRkYqMjIyv0uBg3u4Wm15eHpp3rTX9PTQ0ZLZrHnTXldmZqYuXfw9v8sDkAtN2nRRYKkH5V+shM6d/FkfTZ+gM8ePaNKHn+d3aXAgJtkxsVXO5/3999/Vq1cvxcbGys/PT9WqVdO6devUokULSdLIkSOVnJysgQMH6vLly6pXr57Wr18vHx8fyxzTpk2Ti4uLunXrpuTkZDVr1kzz58+Xs7NzrurO1zW2ffr0kclk0qRJk6zOr1q16r4/ym3+/PkqXLiwzfk9e/ZowIAB97UW/Dv5+RfTy299qB+2rNd/6j2krg1ClZSYoLIVq8kplz/YAPJX6669VCuskcqEVlTj1p00dtpc7d+5TSePHszv0uBACsoDGubOnatz584pJSVF8fHx2rhxo6WpzaozKipKsbGxunHjhrZu3aoqVaxvnvbw8NCsWbP0559/6vr16/ryyy8VHByc6+9Jvie2Hh4emjx5sp577jmbbR4KguLFi+d3CfgXqdWgseZ+vVtXL/8pZ2cXFfL1U0TjKgp84MH8Lg3APShXqZpcXFz16y9nFFqpWn6XAzisfN8VoXnz5goMDLztvmiStGPHDjVs2FCenp4KDg7W0KFDlZSUZLkeGxurNm3ayNPTUyEhIVqyZInKlCmj6dOnW8ZMnTpVVatWlbe3t4KDgzVw4EAlJiZKkrZs2aJnnnlGV69etfyWEhUVJUlW8zz55JPq0aOHVW1paWkqVqyY5s2bJ+nmYukpU6booYcekqenp6pXr67PP+efnpA7fkWKqpCvn3764TtdvfSH6jVuld8lAbgHv5z6WenpaSrKzWTIS/fhAQ1Gk++JrbOzsyZOnKiePXtq6NChKlWqlNX1Q4cOqVWrVnrttdc0d+5cXbx4UYMHD9bgwYMtzeTTTz+tP/74Q1u2bJGrq6uGDRum+Ph4q3mcnJw0c+ZMlSlTRmfPntXAgQM1cuRIvfvuu2rQoIGmT5+ucePG6fjx45KkQoVsF/hHRESoW7duSkxMtFz/5ptvlJSUpC5dukiSXnnlFa1YsUKzZ89WaGiotm3bpqeeekrFixdXo0bZ3/yTkpJi9SSPhISEu/xuIj8lX0/Sb+fPWr6O+/W8Tv98WD5+hVUiqJSuXb2s+NhfdSn+5pYnv547JUkqUqyE/P/ap3bDyk8U/FCo/PyL6diBvfpg8ivq2Os5lQopd/8/EPAvlZyUaP2zfOG8Th87JB+/IipRspQSrlzWxdgL+vOvte8x505L+utnuXiAfjt/VpvWLNcjDZvLt4i/zp8+oQ/eGK9yFauqUs1H8uUzAf8W+d7YSlKnTp1Uo0YNjR8/XnPnzrW69sYbb6hnz56Wm7dCQ0M1c+ZMNWrUSLNnz9a5c+e0ceNG7dmzR3Xq1JEkffjhhwoNDbWa5+83f4WEhOi1117TCy+8oHfffVdubm7y8/OTyWSy7LeWnVatWsnb21srV65Ur169JElLlixRu3bt5Ovrq6SkJE2dOlWbNm1SWFiYJOmhhx7S9u3b9f7779+2sY2Ojtarr76aq+8ZCp6TRw7o5Wc7W77+8I3xkqRm7btr2ISZ2rX5G00f+1/L9ckvPSdJ6vnCCEUMfEmSdOHcKc2fMUGJV6+oxAPB6t4/Uh2ffu4+fgoAJ478pJHPdLJ8/f6UcZKkFh26a8TEWdq1+Ru99cpQy/XoETfvw3hq4Aj1GjRSLq5uOvDDd1q1aI5uXE9SscCSqteohSJeGJHrG2GAf1KQt/vKLwWisZWkyZMnq2nTpho+fLjV+X379unUqVNavHix5ZzZbFZmZqbOnj2rEydOyMXFRbVq1bJcL1eunM163c2bN2vixIk6evSoEhISlJ6erhs3bigpKUne3t45qtHV1VVdu3bV4sWL1atXLyUlJemLL77QkiVLJElHjx7VjRs3rBZMSzf3a8vauy07L7/8soYNG2b5OiEh4a4WTCN/Vav7qNYeuv3uBS069lCLjj1ue12SnnlxrJ55cWxelwYgF6o/8qi+ORJ/2+stO/VQy063/1kuEfSA3lzwhT1KA3AHBaaxbdiwoVq1aqXRo0erT58+lvOZmZl67rnnNHToUJvXPPjgg5alA7cym82W//7ll1/UunVrPf/883rttdfk7++v7du3q2/fvkpLS8tVnREREWrUqJHi4+O1YcMGeXh4KDw83FKrJK1du1YPPPCA1etu96SOrGv/dB0AAOBWJLa2CkxjK0mTJk1SjRo1VL58ecu5WrVq6ciRIypXLvs1hg8//LDS09O1f/9+1a5dW5J06tQpXblyxTJm7969Sk9P11tvvSUnp5v3y3366adW87i5uSkjI+OONTZo0EDBwcFatmyZvv76a3Xt2lVuf22oX6lSJbm7u+v8+fO3XXYAAAAA+yhQjW3VqlUVERGhWbNmWc6NGjVK9evX16BBg9S/f395e3vr2LFj2rBhg2bNmqWHH35YzZs314ABAzR79my5urpq+PDh8vT0tPy2UbZsWaWnp2vWrFlq166dvv/+e7333ntW712mTBklJibq22+/VfXq1eXl5SUvLy+bGk0mk3r27Kn33ntPJ06c0ObNmy3XfHx8NGLECL344ovKzMzUY489poSEBO3YsUOFChVS79697fSdAwAA/zYm083DXnMbUb5v93Wr1157zWoZQbVq1bR161adPHlSjz/+uGrWrKmxY8cqKCjIMmbhwoUKCAhQw4YN1alTJ/Xv318+Pj7y8PCQJNWoUUNTp07V5MmTVaVKFS1evNhme7EGDRro+eefV/fu3VW8ePF/fDZxRESEjh49qgceeECPPvqoTf3jxo1TdHS0KlasqFatWunLL79USEhIXnx7AAAAcBsm89+7SAdx4cIFBQcHa+PGjWrWrFl+l5NrCQkJ8vPz02c7T8mrkM+dXwCgwHJxMmjsAcAiKfGaOtcrq6tXr8rX1ze/y7H0CQ8N+VxO7jm7AT63MlOSdGbWfwrMZ86pArUU4W5t2rRJiYmJqlq1qmJjYzVy5EiVKVNGDRs2zO/SAAAAcJ84RGOblpam0aNH68yZM/Lx8VGDBg20ePFiubq65ndpAAAA9mHHNbY8eSwftWrVSq1a8chRAACAfzOHaGwBAAD+bdjH1laB2xUBAAAAuBsktgAAAAbEPra2SGwBAADgEEhsAQAADMjJySQnO+2VbTboHtw0tgAAAAbEUgRbLEUAAACAQyCxBQAAMCC2+7JFYgsAAACHQGILAABgQKyxtUViCwAAAIdAYgsAAGBArLG1RWILAAAAh0BiCwAAYEAktrZIbAEAAOAQSGwBAAAMiF0RbJHYAgAAwCGQ2AIAABiQSXZcYytjRrYktgAAAHAIJLYAAAAGxBpbWyS2AAAAcAgktgAAAAbEPra2SGwBAADgEEhsAQAADIg1trZobAEAAAyIpQi2WIoAAAAAh0BiCwAAYEAsRbBFYgsAAACHQGILAABgQKyxtUViCwAAAIdAYgsAAGBEdlxjK2MGtiS2AAAAcAwktgAAAAbEGltbJLYAAABwCCS2AAAABsQ+trZIbAEAAOAQSGwBAAAMiDW2tkhsAQAA4BBIbAEAAAyINba2SGwBAABw16Kjo1W3bl35+PioRIkS6tixo44fP241pk+fPpalE1lH/fr1rcakpKRoyJAhKlasmLy9vdW+fXtduHAhV7XQ2AIAABjQrY1iXh85tXXrVg0aNEi7du3Shg0blJ6erpYtWyopKclq3BNPPKHY2FjL8dVXX1ldj4yM1MqVK7V06VJt375diYmJatu2rTIyMnJcC0sRAAAADOh+3DyWkJBgdd7d3V3u7u5W59atW2f19bx581SiRAnt27dPDRs2tHptYGBgtu939epVzZ07Vx9//LGaN28uSVq0aJGCg4O1ceNGtWrVKkd1k9gCAAAgW8HBwfLz87Mc0dHRd3zN1atXJUn+/v5W57ds2aISJUqofPny6t+/v+Lj4y3X9u3bp7S0NLVs2dJyrmTJkqpSpYp27NiR43pJbAEAAAzoftw8FhMTI19fX8v5W9PaW5nNZg0bNkyPPfaYqlSpYjkfHh6url27qnTp0jp79qzGjh2rpk2bat++fXJ3d1dcXJzc3NxUpEgRq/kCAgIUFxeX47ppbAEAAJAtX19fq8b2TgYPHqyDBw9q+/btVue7d+9u+e8qVaqoTp06Kl26tNauXavOnTvfdj6z2Zyr5RYsRQAAADCggnLzWJYhQ4Zo9erV2rx5s0qVKvWPY4OCglS6dGmdPHlSkhQYGKjU1FRdvnzZalx8fLwCAgJyXAONLQAAAO6a2WzW4MGDtWLFCm3atEkhISF3fM2ff/6pmJgYBQUFSZJq164tV1dXbdiwwTImNjZWhw8fVoMGDXJcC0sRAAAADKigPKBh0KBBWrJkib744gv5+PhY1sT6+fnJ09NTiYmJioqKUpcuXRQUFKRz585p9OjRKlasmDp16mQZ27dvXw0fPlxFixaVv7+/RowYoapVq1p2ScgJGlsAAADctdmzZ0uSGjdubHV+3rx56tOnj5ydnXXo0CEtXLhQV65cUVBQkJo0aaJly5bJx8fHMn7atGlycXFRt27dlJycrGbNmmn+/PlydnbOcS00tgAAAAZ0P/axzQmz2fyP1z09PfXNN9/ccR4PDw/NmjVLs2bNyvF734o1tgAAAHAIJLYAAAAGZJId19jaZ1q7I7EFAACAQyCxBQAAMCAnk0lOdops7TWvvZHYAgAAwCGQ2AIAABhQQdnHtiAhsQUAAIBDILEFAAAwoIKyj21BQmILAAAAh0BiCwAAYEBOppuHveY2IhpbAAAAIzLZccmAQRtbliIAAADAIZDYAgAAGBDbfdkisQUAAIBDILEFAAAwINNff+w1txGR2AIAAMAhkNgCAAAYENt92SKxBQAAgEMgsQUAADAgHqlri8QWAAAADoHEFgAAwIDYx9YWiS0AAAAcAoktAACAATmZTHKyU7Rqr3ntjcQWAAAADoHEFgAAwIBYY2uLxBYAAAAOgcQWAADAgNjH1haJLQAAABwCiS0AAIABscbWFo0tAACAAbHdl60cNbYzZ87M8YRDhw6962IAAACAu5WjxnbatGk5msxkMtHYAgAA3Aemvw57zW1EOWpsz549a+86AAAAgHty17sipKam6vjx40pPT8/LegAAAJADWdt92eswolw3ttevX1ffvn3l5eWlypUr6/z585Jurq2dNGlSnhcIAAAA5ESuG9uXX35ZP/30k7Zs2SIPDw/L+ebNm2vZsmV5WhwAAACy52Sy72FEud7ua9WqVVq2bJnq169vFVNXqlRJp0+fztPiAAAAgJzKdWN78eJFlShRwuZ8UlKSYddjAAAAGA2P1LWV66UIdevW1dq1ay1fZ33wOXPmKCwsLO8qAwAAAHIh14ltdHS0nnjiCR09elTp6emaMWOGjhw5op07d2rr1q32qBEAAADZMGiwaje5TmwbNGig77//XtevX1fZsmW1fv16BQQEaOfOnapdu7Y9agQAAADuKNeJrSRVrVpVCxYsyOtaAAAAkEOssbV1V41tRkaGVq5cqWPHjslkMqlixYrq0KGDXFzuajoAAADgnuW6Ez18+LA6dOiguLg4VahQQZJ04sQJFS9eXKtXr1bVqlXzvEgAAABYs+d+s0bdxzbXa2z79eunypUr68KFC/rxxx/1448/KiYmRtWqVdOAAQPsUSMAAABwR7lObH/66Sft3btXRYoUsZwrUqSIJkyYoLp16+ZpcQAAAMgea2xt5TqxrVChgn7//Xeb8/Hx8SpXrlyeFAUAAADkVo4S24SEBMt/T5w4UUOHDlVUVJTq168vSdq1a5f+7//+T5MnT7ZPlQAAALBi+uuw19xGlKPGtnDhwlaRtNlsVrdu3SznzGazJKldu3bKyMiwQ5kAAAD4OyeTSU52WjJgr3ntLUeN7ebNm+1dBwAAAHBPctTYNmrUyN51AAAAIBdMJvs9UteggW3ubx7Lcv36df388886ePCg1QEAAIB/j+joaNWtW1c+Pj4qUaKEOnbsqOPHj1uNMZvNioqKUsmSJeXp6anGjRvryJEjVmNSUlI0ZMgQFStWTN7e3mrfvr0uXLiQq1py3dhevHhRbdu2lY+PjypXrqyaNWtaHQAAALC/rO2+7HXk1NatWzVo0CDt2rVLGzZsUHp6ulq2bKmkpCTLmClTpmjq1Kl6++23tWfPHgUGBqpFixa6du2aZUxkZKRWrlyppUuXavv27UpMTFTbtm1zdf9WrhvbyMhIXb58Wbt27ZKnp6fWrVunBQsWKDQ0VKtXr87tdAAAADCwdevWqU+fPqpcubKqV6+uefPm6fz589q3b5+km2nt9OnTNWbMGHXu3FlVqlTRggULdP36dS1ZskSSdPXqVc2dO1dvvfWWmjdvrpo1a2rRokU6dOiQNm7cmONact3Ybtq0SdOmTVPdunXl5OSk0qVL66mnntKUKVMUHR2d2+kAAABwF7LW2NrrkG5u+fr3IyUl5Y51Xb16VZLk7+8vSTp79qzi4uLUsmVLyxh3d3c1atRIO3bskCTt27dPaWlpVmNKliypKlWqWMbkRK4b26SkJJUoUcJS8MWLFyVJVatW1Y8//pjb6QAAAFBABQcHy8/Pz3LcKcQ0m80aNmyYHnvsMVWpUkWSFBcXJ0kKCAiwGhsQEGC5FhcXJzc3N6sn2946Jidy/UjdChUq6Pjx4ypTpoxq1Kih999/X2XKlNF7772noKCg3E4HAACAu3A/9rGNiYmRr6+v5by7u/s/vm7w4ME6ePCgtm/fbnPt1nW7ZrP5jmt5czLm73Ld2EZGRio2NlaSNH78eLVq1UqLFy+Wm5ub5s+fn9vpAAAAUED5+vpaNbb/ZMiQIVq9erW2bdumUqVKWc4HBgZKupnK/j0EjY+Pt6S4gYGBSk1N1eXLl61S2/j4eDVo0CDH9eZ6KUJERIT69OkjSapZs6bOnTunPXv2KCYmRt27d8/tdAAAALgL92ONbU6YzWYNHjxYK1as0KZNmxQSEmJ1PSQkRIGBgdqwYYPlXGpqqrZu3WppWmvXri1XV1erMbGxsTp8+HCuGttcJ7a38vLyUq1ate51GgAAABjQoEGDtGTJEn3xxRfy8fGxrIn18/OTp6enTCaTIiMjNXHiRIWGhio0NFQTJ06Ul5eXevbsaRnbt29fDR8+XEWLFpW/v79GjBihqlWrqnnz5jmuJUeN7bBhw3I84dSpU3M8FgAAAHcnt/vN5nbunJo9e7YkqXHjxlbn582bZ/lX/pEjRyo5OVkDBw7U5cuXVa9ePa1fv14+Pj6W8dOmTZOLi4u6deum5ORkNWvWTPPnz5ezs3OOa8lRY7t///4cTWavby4AAAAKJrPZfMcxJpNJUVFRioqKuu0YDw8PzZo1S7NmzbrrWnLU2G7evPmu3wB3r2H54jlesA2gYCpSd3B+lwDgHpkzUvO7hGw56S5ulsrF3EZk1LoBAAAAK/d88xgAAADuv4KyxrYgobEFAAAwIJNJcrJT/2nQvpalCAAAAHAMJLYAAAAG5GTHxNZe89rbXSW2H3/8sR599FGVLFlSv/zyiyRp+vTp+uKLL/K0OAAAACCnct3Yzp49W8OGDVPr1q115coVZWRkSJIKFy6s6dOn53V9AAAAyEbWzWP2Oowo143trFmzNGfOHI0ZM8bqSRB16tTRoUOH8rQ4AAAAIKdyvcb27Nmzqlmzps15d3d3JSUl5UlRAAAA+GessbWV68Q2JCREBw4csDn/9ddfq1KlSnlREwAAAJBruU5sX3rpJQ0aNEg3btyQ2WzW7t279cknnyg6OloffvihPWoEAADALUwm++03a9AltrlvbJ955hmlp6dr5MiRun79unr27KkHHnhAM2bMUI8ePexRIwAAAHBHd7WPbf/+/dW/f3/98ccfyszMVIkSJfK6LgAAAPwDJ5NJTnaKVu01r73d0wMaihUrlld1AAAAAPck141tSEjIP+5tdubMmXsqCAAAAHfmpLt80lYO5zaiXDe2kZGRVl+npaVp//79WrdunV566aW8qgsAAADIlVw3tv/973+zPf/OO+9o796991wQAAAA7oxdEWzlWdIcHh6u5cuX59V0AAAAQK7c081jf/f555/L398/r6YDAADAP3CSHXdFkDEj21w3tjVr1rS6ecxsNisuLk4XL17Uu+++m6fFAQAAADmV68a2Y8eOVl87OTmpePHiaty4sR5++OG8qgsAAAD/gDW2tnLV2Kanp6tMmTJq1aqVAgMD7VUTAAAA7sDJdPOw19xGlKubx1xcXPTCCy8oJSXFXvUAAAAAdyXXuyLUq1dP+/fvt0ctAAAAyCGT6f8/Vjevj3/FUgRJGjhwoIYPH64LFy6odu3a8vb2trperVq1PCsOAAAAyKkcN7bPPvuspk+fru7du0uShg4darlmMplkNptlMpmUkZGR91UCAADACjeP2cpxY7tgwQJNmjRJZ8+etWc9AAAAwF3JcWNrNpslSaVLl7ZbMQAAAMgZdkWwlaubx0xGzaUBAADg8HJ181j58uXv2NxeunTpngoCAADAnZn++mOvuY0oV43tq6++Kj8/P3vVAgAAANy1XDW2PXr0UIkSJexVCwAAAHKINba2crzGlvW1AAAAKMhyvSsCAAAA8h+Jra0cN7aZmZn2rAMAAAC4J7l+pC4AAADyn8lksttSUaMuQc3VPrYAAABAQUViCwAAYECssbVFYgsAAACHQGILAABgQCbTzcNecxsRjS0AAIABOZlMcrJTB2qvee2NpQgAAABwCCS2AAAABsTNY7ZIbAEAAOAQSGwBAACMyI43j4nEFgAAAMg/JLYAAAAG5CSTnOwUrdprXnsjsQUAAIBDILEFAAAwIB7QYIvEFgAAAA6BxBYAAMCA2MfWFoktAAAA7sm2bdvUrl07lSxZUiaTSatWrbK63qdPH5lMJqujfv36VmNSUlI0ZMgQFStWTN7e3mrfvr0uXLiQqzpobAEAAAzIyWSy65EbSUlJql69ut5+++3bjnniiScUGxtrOb766iur65GRkVq5cqWWLl2q7du3KzExUW3btlVGRkaO62ApAgAAAO5JeHi4wsPD/3GMu7u7AgMDs7129epVzZ07Vx9//LGaN28uSVq0aJGCg4O1ceNGtWrVKkd1kNgCAAAYUNauCPY6JCkhIcHqSElJuet6t2zZohIlSqh8+fLq37+/4uPjLdf27duntLQ0tWzZ0nKuZMmSqlKlinbs2JHj96CxBQAAQLaCg4Pl5+dnOaKjo+9qnvDwcC1evFibNm3SW2+9pT179qhp06aWRjkuLk5ubm4qUqSI1esCAgIUFxeX4/dhKQIAAIABOSn3a2FzM7ckxcTEyNfX13Le3d39rubr3r275b+rVKmiOnXqqHTp0lq7dq06d+5829eZzWaZcvEZSWwBAACQLV9fX6vjbhvbWwUFBal06dI6efKkJCkwMFCpqam6fPmy1bj4+HgFBATkeF4aWwAAAAO6H2ts7eXPP/9UTEyMgoKCJEm1a9eWq6urNmzYYBkTGxurw4cPq0GDBjmel6UIAAAABuQk+yWUuZ03MTFRp06dsnx99uxZHThwQP7+/vL391dUVJS6dOmioKAgnTt3TqNHj1axYsXUqVMnSZKfn5/69u2r4cOHq2jRovL399eIESNUtWpVyy4JOUFjCwAAgHuyd+9eNWnSxPL1sGHDJEm9e/fW7NmzdejQIS1cuFBXrlxRUFCQmjRpomXLlsnHx8fymmnTpsnFxUXdunVTcnKymjVrpvnz58vZ2TnHddDYAgAAGFDWE7zsNXduNG7cWGaz+bbXv/nmmzvO4eHhoVmzZmnWrFm5eu+/Y40tAAAAHAKJLQAAgAGZ/jrsNbcRkdgCAADAIZDYAgAAGJCTyY4PaLD3fl92QmILAAAAh0BiCwAAYFDGzFXth8QWAAAADoHEFgAAwIDs+ehbgy6xJbEFAACAYyCxBQAAMKCC9OSxgoLEFgAAAA6BxBYAAMCAnGS/hNKoyadR6wYAAACskNgCAAAYEGtsbZHYAgAAwCGQ2AIAABiQSfZ78pgx81oaWwAAAENiKYItliIAAADAIZDYAgAAGBDbfdkyat0AAACAFRJbAAAAA2KNrS0SWwAAADgEElsAAAADYrsvWyS2AAAAcAgktgAAAAZkMt087DW3EZHYAgAAwCGQ2AIAABiQk0xystNqWHvNa28ktgAAAHAIJLYAAAAGxBpbWyS2AAAAcAgktgAAAAZk+uuPveY2IhJbAAAAOAQSWwAAAANija0tGlsAAAADMtlxuy+WIgAAAAD5iMQWAADAgFiKYIvEFgAAAA6BxBYAAMCASGxtkdgCAADAIZDYAgAAGBAPaLBFYgsAAACHQGILAABgQE6mm4e95jYiElsAAAA4BBJbAAAAA2KNrS0SWwAAADgEElsAAAADYh9bWyS2AAAAcAgktgAAAAZkkv3Wwho0sCWxBQAAgGMgsQXuozcmR2vVyhU6cfxneXp6ql5YA02YOFnlK1TI79IA/KV/18fU/z+Pq3RJf0nSsTNxmvjB11r//VFJkrenm14f2kHtmlSTv5+3fvntkt5dukVzPttumSOgqI8mRnZS0/oPy8fbXSfOxeuNj77Ryo0H8uMjwUGxj60tGlvgPvpu21Y9/8Ig1a5TV+np6YoaN0ZtW7fU/oNH5e3tnd/lAZD06+9XNHbWFzp9/g9J0lPt6umzaQNUv8ckHTsTpykjuqhRnfJ6ZsxC/fLbn2oeVlEzXu6m2ItXtWbLIUnS3Nd7y6+Qh7pGvq8/riSqe3gdfTzpWT0aMUU/Hb+Qnx8PcGgsRQDuo9Vr16lX7z6qVLmyqlWvrvc/nKeY8+e1/8d9+V0agL98te2wvtl+VKfOx+vU+XhFvfOlEq+n6JFqIZKketVCtGjND/pu30mdj72kj1Z8r4MnflWtSg9a5qhXLUTvLt2qvUd+0blf/9TkD7/RlWvJqlExOL8+FhyQyc5/jIjGFshHCVevSpKKFPHP50oAZMfJyaSurWrL29NNPxw8K0naceCM2jaqqpLF/SRJDeuEKrR0CW3ccczyuh37T+s/LWuriK+XTKabc7i7uWjb3pP58jngmLK2+7LXkRvbtm1Tu3btVLJkSZlMJq1atcrqutlsVlRUlEqWLClPT081btxYR44csRqTkpKiIUOGqFixYvL29lb79u114ULu/oXjX9vYnjt3TiaTSQcOHPjHcY0bN1ZkZOR9qQn/LmazWaNeGqYGjz6mylWq5Hc5AP6mcrmSuvj9W7r6w3TNHNNd3YfP0c9n4iRJwyd/pmNn4nR6/QQl7J6h1e8M1H+jl2nHgTOW1/f630dycXbSb1un6OoP0zVrTA91HzZHZy/8kV8fCbCrpKQkVa9eXW+//Xa216dMmaKpU6fq7bff1p49exQYGKgWLVro2rVrljGRkZFauXKlli5dqu3btysxMVFt27ZVRkZGjuso8Gts+/TpowULFkiSXFxcFBwcrM6dO+vVV1+9pzWJwcHBio2NVbFixSRJW7ZsUZMmTXT58mUVLlzYMm7FihVydXW9p88AZOfFoYN16NBBfbtl+50HA7ivTpz7XfV6RKuwj5c6NquhOf/XSy37zdDPZ+I06MnGeqRqGXX573s6H3tJj9Uqpxkvd1fcHwna/MNxSVLUoHYq4uul8Odm6s8rSWrXuJoWv/Gsmj87XUdO/ZbPnw6OwiT7bcuV23nDw8MVHh6e7TWz2azp06drzJgx6ty5syRpwYIFCggI0JIlS/Tcc8/p6tWrmjt3rj7++GM1b95ckrRo0SIFBwdr48aNatWqVY7qKPCNrSQ98cQTmjdvntLS0vTdd9+pX79+SkpK0uzZs+96TmdnZwUGBt5xnL8//0SMvPfif4dozZrV2rhpm0qVKpXf5QC4RVp6hs7E3ExXfzx6XrUrP6hBTzbWS28u16tD2qn7sDlat/3mP6MePvmbqlUopchezbT5h+MKKVVML/RopFpdXtexv1LeQyd+1aO1yuq57g01dMLSfPtcQG4lJCRYfe3u7i53d/dczXH27FnFxcWpZcuWVvM0atRIO3bs0HPPPad9+/YpLS3NakzJkiVVpUoV7dixI8eNrSGWIri7uyswMFDBwcHq2bOnIiIitGrVKqWkpGjo0KEqUaKEPDw89Nhjj2nPnj2W112+fFkREREqXry4PD09FRoaqnnz5kmyXopw7tw5NWnSRJJUpEgRmUwm9enTR5L1UoSXX35Z9evXt6mvWrVqGj9+vOXrefPmqWLFivLw8NDDDz+sd999107fGRiN2WxW5NDB+mLVCq1bv0llQkLyuyQAOWCSSe5uLnJ1cZabq4syzWar6xkZmXL6a38kLw83ScpmjFlORn1OKQokJ5nkZLLT8VdmGxwcLD8/P8sRHR2d6zrj4m7+ghcQEGB1PiAgwHItLi5Obm5uKlKkyG3H5IQhEttbeXp6Ki0tTSNHjtTy5cu1YMEClS5dWlOmTFGrVq106tQp+fv7a+zYsTp69Ki+/vprFStWTKdOnVJycrLNfMHBwVq+fLm6dOmi48ePy9fXV56enjbjIiIiNGnSJJ0+fVply5aVJB05ckSHDh3S559/LkmaM2eOxo8fr7fffls1a9bU/v371b9/f3l7e6t3797Zfp6UlBSlpKRYvr71tyM4jsghg7Rs6RJ9tuILFfLxsfyw+vn5Zft/cwDuv1cHt9P6748qJu6yfLw91LVVbTWsE6r2g97VtaQb2rb3pCZGdlTyjTSdj72kx2uXU0TbRzRq6gpJ0vFzcTp1Pl5vv/KkXp66Un9eTVL7JtXUrH4Fdf7ve/n86YDciYmJka+vr+Xr3Ka1f2e65Rc7s9lsc+5WORnzd4ZrbHfv3q0lS5aoSZMmmj17tubPn29Z0zFnzhxt2LBBc+fO1UsvvaTz58+rZs2aqlOnjiSpTJky2c7p7OxsWXJQokQJqzW2f1elShVVq1ZNS5Ys0dixYyVJixcvVt26dVW+fHlJ0muvvaa33nrLsoYkJCRER48e1fvvv3/bxjY6OlqvvvrqXX0/YCwfvH9z+UzLZo2tz384T71697n/BQGwUaKoj+a+/rQCi/nqauINHT75q9oPelebfvhZkvT0/z7S/w3poPkTe6uIr5fOx15S1DtrLA9oSE/PVMchs/X60A76fMZzKuTlrtMxF9Vv3Mf6ZvvR/PxocDD3Y42tr6+vVWN7N7KWfsbFxSkoKMhyPj4+3pLiBgYGKjU1VZcvX7ZKbePj49WgQYMcv5chGts1a9aoUKFCSk9PV1pamjp06KAhQ4bo888/16OPPmoZ5+rqqkceeUTHjt3ccuWFF15Qly5d9OOPP6ply5bq2LFjrr452YmIiNBHH32ksWPHymw265NPPrEsVbh48aJiYmLUt29f9e/f3/Ka9PR0+fn53XbOl19+WcOGDbN8nZCQoOBg9jp0RMlp5jsPApCvXnh1yT9e//3Pa3ouatE/jjl9/qKeHPFhXpYFGFZISIgCAwO1YcMG1axZU5KUmpqqrVu3avLkyZKk2rVry9XVVRs2bFC3bt0kSbGxsTp8+LCmTJmS4/cyRGOblc66urqqZMmScnV11U8//STpn2Pt8PBw/fLLL1q7dq02btyoZs2aadCgQXrzzTfvupaePXvqf//7n3788UclJycrJiZGPXr0kCRlZmZKupkc16tXz+p1zs7Ot53zbhZiAwCAf7kCtC1CYmKiTp06Zfn67NmzOnDggPz9/fXggw8qMjJSEydOVGhoqEJDQzVx4kR5eXmpZ8+ekm4uyevbt6+GDx+uokWLyt/fXyNGjFDVqlUtuyTkhCEaW29vb5UrV87qXLly5eTm5qbt27dbvilpaWnau3ev1b6zxYsXV58+fdSnTx89/vjjeumll7JtbN3cbi72v9NeaaVKlVLDhg21ePFiJScnq3nz5pYYPSAgQA888IDOnDmjiIiIe/nIAAAAhrF3717LjfiSLP8S3bt3b82fP18jR45UcnKyBg4cqMuXL6tevXpav369fHx8LK+ZNm2aXFxc1K1bNyUnJ6tZs2aaP3/+P4aDtzJEY5sdb29vvfDCC3rppZcsvw1MmTJF169fV9++fSVJ48aNU+3atVW5cmWlpKRozZo1qlixYrbzlS5dWiaTSWvWrFHr1q3l6empQoUKZTs2IiJCUVFRSk1N1bRp06yuRUVFaejQofL19VV4eLhSUlK0d+9eXb582Wq5AQAAwL2w56Nvcztv48aNZTbffrmdyWRSVFSUoqKibjvGw8NDs2bN0qxZs3L13n9niO2+bmfSpEnq0qWLevXqpVq1aunUqVP65ptvLIuO3dzc9PLLL6tatWpq2LChnJ2dtXRp9vsHPvDAA3r11Vf1v//9TwEBARo8ePBt37dr1676888/df36dXXs2NHqWr9+/fThhx9q/vz5qlq1qho1aqT58+crhG2dAAAA7Mpk/qf2GvkiISFBfn5++v3Pq/d8JyKA/FWk7u1/SQZgDOaMVKUcmqOrVwvG38tZfcK3B86rkI996km8lqBmNR4sMJ85pwyd2AIAAABZDLvGFgAA4N+sAG2KUGCQ2AIAAMAhkNgCAAAYEZGtDRJbAAAAOAQSWwAAAAMqSPvYFhQ0tgAAAAZkMt087DW3EbEUAQAAAA6BxBYAAMCAuHfMFoktAAAAHAKJLQAAgBER2dogsQUAAIBDILEFAAAwILb7skViCwAAAIdAYgsAAGBA7GNri8QWAAAADoHEFgAAwIDYFMEWiS0AAAAcAoktAACAERHZ2iCxBQAAgEMgsQUAADAg9rG1RWILAAAAh0BiCwAAYEDsY2uLxBYAAAAOgcQWAADAgNgUwRaNLQAAgBHR2dpgKQIAAAAcAoktAACAAbHdly0SWwAAADgEElsAAAADYrsvWyS2AAAAcAgktgAAAAbEpgi2SGwBAADgEEhsAQAAjIjI1gaJLQAAABwCiS0AAIABsY+tLRJbAAAAOAQSWwAAAANiH1tbJLYAAABwCCS2AAAABsSmCLZIbAEAAOAQSGwBAACMiMjWBoktAAAAHAKJLQAAgAGxj60tGlsAAAAjsuN2Xwbta1mKAAAAAMdAYgsAAGBA3Dtmi8QWAAAADoHEFgAAwIiIbG2Q2AIAAMAh0NgCAAAYkMnOf3IqKipKJpPJ6ggMDLRcN5vNioqKUsmSJeXp6anGjRvryJEj9viW0NgCAADg3lSuXFmxsbGW49ChQ5ZrU6ZM0dSpU/X2229rz549CgwMVIsWLXTt2rU8r4M1tgAAAAZksuM+trmd18XFxSqlzWI2mzV9+nSNGTNGnTt3liQtWLBAAQEBWrJkiZ577rm8KNeCxBYAAADZSkhIsDpSUlKyHXfy5EmVLFlSISEh6tGjh86cOSNJOnv2rOLi4tSyZUvLWHd3dzVq1Eg7duzI83ppbAEAAAzIZOdDkoKDg+Xn52c5oqOjbeqoV6+eFi5cqG+++UZz5sxRXFycGjRooD///FNxcXGSpICAAKvXBAQEWK7lJZYiAAAAIFsxMTHy9fW1fO3u7m4zJjw83PLfVatWVVhYmMqWLasFCxaofv36kiTTLWsbzGazzbm8QGILAABgRPchsvX19bU6smtsb+Xt7a2qVavq5MmTlnW3t6az8fHxNiluXqCxBQAAQJ5JSUnRsWPHFBQUpJCQEAUGBmrDhg2W66mpqdq6dasaNGiQ5+/NUgQAAAADyu1+s7mdO6dGjBihdu3a6cEHH1R8fLxef/11JSQkqHfv3jKZTIqMjNTEiRMVGhqq0NBQTZw4UV5eXurZs2ee101jCwAAgLt24cIFPfnkk/rjjz9UvHhx1a9fX7t27VLp0qUlSSNHjlRycrIGDhyoy5cvq169elq/fr18fHzyvBYaWwAAAAMyyY772OZi7NKlS/95LpNJUVFRioqKuqeacoLGFgAAwID+vi2XPeY2Im4eAwAAgEMgsQUAADCggvRI3YKCxBYAAAAOgcQWAADAkFhleysSWwAAADgEElsAAAADYo2tLRJbAAAAOAQSWwAAAANiha0tElsAAAA4BBJbAAAAA2KNrS0SWwAAADgEElsAAAADMv31x15zGxGJLQAAABwCiS0AAIARsS2CDRJbAAAAOAQSWwAAAAMisLVFYgsAAACHQGILAABgQOxja4vGFgAAwIDY7ssWSxEAAADgEEhsAQAAjIi7x2yQ2AIAAMAhkNgCAAAYEIGtLRJbAAAAOAQSWwAAAANiuy9bJLYAAABwCCS2AAAAhmS/fWyNusqWxBYAAAAOgcQWAADAgFhja4vEFgAAAA6BxhYAAAAOgcYWAAAADoE1tgAAAAbEGltbJLYAAABwCCS2AAAABmSy4z629tsf175IbAEAAOAQSGwBAAAMiDW2tmhsAQAADMgk+z341qB9LUsRAAAA4BhIbAEAAIyIyNYGiS0AAAAcAoktAACAAbHdly0SWwAAADgEElsAAAADYrsvWyS2AAAAcAgktgAAAAbEpgi2SGwBAADgEEhsAQAAjIjI1gaJLQAAABwCiS0AAIABsY+tLRJbAAAAOAQSWwAAAANiH1tbNLYFkNlsliRdS0jI50oA3CtzRmp+lwDgHmX9HGf9/VxQJNixT7Dn3PZEY1sAXbt2TZJULiQ4nysBAABZrl27Jj8/v/wuQ25ubgoMDFSonfuEwMBAubm52fU98prJXNB+/YAyMzP122+/ycfHRyaj/lsA/lFCQoKCg4MVExMjX1/f/C4HwF3iZ/nfwWw269q1aypZsqScnArG7Uk3btxQaqp9/0XIzc1NHh4edn2PvEZiWwA5OTmpVKlS+V0G7gNfX1/+MgQcAD/Ljq8gJLV/5+HhYbim834oGL92AAAAAPeIxhYAAAAOgcYWyAfu7u4aP3683N3d87sUAPeAn2WgYOHmMQAAADgEElsAAAA4BBpbAAAAOAQaWwAAADgEGlsAAAA4BBpbAAAAOAQaWwAAADgEGlsAAAA4BBpbwGAyMzPzuwQAAAokl/wuAEDOZWZmysnp5u+jmzdvVkxMjAIDAxUSEqLQ0NB8rg7AnZjNZplMJl26dEnp6elydXVVkSJFrK4BuHs8eQwwoFGjRmnZsmUKDAyUk5OTbty4ocmTJ6tFixb5XRqA28hqXL/44gvNmDFDZ86cUfXq1VWlShVNmDAhv8sDHAJLEQCDmT9/vj7++GMtWbJEu3btUvv27XX06FElJSXld2kA/oHJZNLXX3+tHj16qEOHDlq2bJmqVq2q6Ohoff311/ldHuAQSGwBg8hKe1588UVJ0rRp07Rq1So9/fTTevPNNzVgwABdv35df/zxhx588MF8rhbArVJTU/Xcc8+pbNmyeuWVV3Tx4kXVqlVLnTp10syZM/O7PMAhkNgCBdjff+9MT0+XJCUmJqpcuXJav369evXqpTfeeEMDBgxQZmamli9frnXr1iklJSW/SgZwG87Ozjp+/LhCQkIUGxurmjVrKjw83NLUfvbZZ/r222/zuUrA2GhsgQIs60aS9957T5s3b5YklSxZUsOHD7ekPM8995wkKSEhQQsXLlRsbKzc3d3zrWYA1g4fPqzTp09LkkqXLq3du3fr0UcfVevWrfXBBx9Iki5fvqx169bpxIkTysjIyM9yAUNjKQJgANWqVVOpUqX01VdfSZK6d++udevWaevWrSpWrJjS09P1/PPP69KlS9qxY4dcXNjwBMhvZrNZv/32mxo2bKhJkyapa9euWrp0qXr27KnatWtr06ZN8vHxkSSNGTNGS5cu1YYNG/TQQw/lc+WAcdHYAgVY1vZemzdv1pAhQzR58mS1adNGp0+f1pAhQ7Rr1y55eHioVKlScnFx0datW+Xq6qqMjAw5Ozvnd/kAJEVEROjQoUP64Ycf5OnpqXfeeUdDhgzRk08+KScnJ5nNZq1du1abNm1SzZo187tcwNBobIEC5O/71P7dr7/+qieffFK1a9fWtGnTLOfXrVunGzduqEiRInr88cfl5OSk9PR0ElsgH9z6C2Vqaqrc3Nx04MABDRgwQJGRkerZs6ckafXq1VqzZo1+++03Va9eXb169dLDDz+cX6UDDoPGFigAFixYoDZt2qhYsWKSpGXLlunq1asaMGCAZcynn36qp59+Wlu3blW9evWyned2jTEA+/n555+tmtITJ04oNDTUskY+OTlZnTt3lru7u1atWmUZl9UI82AGIO/wNyCQzxYsWKDFixfL399fkhQfH69PPvlEL7/8slq0aKEFCxbo0qVL6tatm1q3bq2VK1cqJSUl20fr0tQC99esWbM0fvx4JSYmSpJOnz6trl27qlKlSvrmm2905swZeXp6Kjo6Wtu3b9eiRYssr836eaWpBfIOiS1QAGQlN999953q1KkjNzc3XbhwQZGRkYqPj9fFixc1a9YsffbZZ/rxxx+1ceNGSyMMIP/s3r1bRYoUUWhoqK5cuSJfX1/99NNPevPNN3Xo0CG5urpq4MCBatq0qSZNmiRPT0+98cYbcnZ25hdRwA5obIF8lJKSYtmaa/fu3Xrsscc0ZswY9evXTw888IDS09N17Ngxvfvuu9q2bZsCAwO1efNmTZkyRSNGjMjn6oF/t78v/dm1a5fGjx+vYcOGqVWrVpKkTZs26fvvv9eUKVPUvn17HThwQGfOnNH+/ftZTwvYCXeYAPkkPT3d0tRu375djz32mMaNG6e5c+fKxcVFvXv3VqlSpVS1alXNnj1b27Zt08GDB+Xu7q7IyMj8LR74l/p7M5v139evX5ePj48uXryo999/X+np6WrTpo2aNm2qpk2bqm3btvriiy/0888/KyUlhZs7ATsisQXywbp16xQVFaVdu3Zp2LBh+vbbb/Xdd9/J19dXr7/+ut5//309//zzevbZZxUUFJTtHOx+AOSPEydOKDY2Vo0aNdJnn32mTz75RCtWrNCuXbs0cuRIFS5cWAMHDtQTTzxheU1GRobS0tL0xx9/qFSpUvlYPeDY+FsRuM8yMzNlMpl09epVlS1bVpcuXdK+ffvk6+srSXrllVck3XzamCT17dtXgYGBNvPQ1AL3X2Zmpt555x3LTWOvvvqq5s2bJ0mqX7++Jk+erFGjRundd9+VyWSyLEswm82WPacB2A+JLZBPnn76aS1atEi1a9fWnj17JFmvuZ0wYYLmzJmj7t27a+TIkSpatGh+lgv8qy1atEidOnWSt7e3JKlhw4bauXOnRowYoejoaKWnp8vZ2Vkmk0k7d+7UqFGjVKxYMT3zzDNq165dPlcP/HtwSyZwn2VmZio9PV1t27bVe++9p7S0NDVs2FCZmZlyd3fX9evXJd18xObTTz+tn3/+mR0QgHx05swZjRo1ShcvXpT0/38BrVGjhqZPn65vv/1WLi4uysjIUGZmpsLCwjRlyhSdOnVKixcvVlJSUj5/AuDfg8QWuA9u9+CEzMxMrVu3zpLIbt261XLt66+/Vnh4uGXzdjZxB/JPUlKSvL29deDAAVWsWNFyfuDAgVqyZInWrFmjZs2aWT104cSJE/Lw8FDp0qXzsXLg34XGFrCzvze1S5Ys0dGjR+Xs7Kx27dqpTp06SklJ0ebNm/XSSy/J29tbH3zwgUaMGKGMjAxt3LiRphYoAMxms65cuaJSpUqpZcuWWrx4sby8vHTp0iW99NJL+uSTT7R69Wo1b95c0dHR2r9/vxYvXixXV9f8Lh34V6GxBe6TUaNGaenSpapcubI8PT21fv16rVixQi1atFBqaqp27NihESNG6OLFiypdurS+/fZbubq60tQC+Sjr5y8rid28ebO6du2qVq1aac6cOZbmdvTo0frggw/UpEkTff/999q5c6dq1qyZ3+UD/zo0tsB98MEHH+j111/X8uXLVbduXX3yySeKiIiQs7OzPv30U3Xq1Elms1lpaWk6cuSIqlevLicnJ7b0AvJRVlO7Y8cOnThxQq1bt1aJEiX0/fffq02bNmrdurXmzJljuaHsk08+0fnz59W5c2eFhobmc/XAvxONLWBnCQkJmjBhgipUqKBnn31Wa9asUUREhKKionT06FEtXLhQq1evtmwLlOV263IB2F9WU7t8+XL17dtXI0aMUJcuXSzra7dv3642bdqoTZs2+uCDD1SoUCGr1wHIHzS2QB7LriE9ePCgvL29lZmZqbZt22rw4MEaMmSI1qxZo/bt20uSNm/erEaNGuVHyQCysW3bNnXo0EFvvPGG+vXrZzl//fp1eXl5aevWrercubMeffRRLVmyxNLcAsg//BsnkIfMZrPVjWJeXl7q0KGDqlWrJklas2aNihYtqoiICElS4cKFNWDAANWuXVuPPvpovtUNwNaGDRvUsGFD9evXT0lJSdq9e7cWLlyoK1euaNCgQWrevLk+++wzPfPMM0pISKCxBQoAGlsgj/w9qT137pyGDRumqlWrqlChQmrevLkk6dq1a9q1a5fOnj2rzMxMTZkyRcWLF1f//v0l8ZhcoCDx9vZWbGysPvroI61du1YpKSlKTExUUFCQIiIitGfPHjVt2lQ///yzPD0987tcAGIpApDnRo4cqT/++EP79u3T6dOnVb58eU2aNEktWrRQSkqKIiIitHLlSpUrV07u7u768ccf2f0AyGfZ/fzt3r1b0dHR2rt3r5o1a6aIiAi1aNFCGzdu1NixY7V69WoVL148nyoGkB2iISAPvf/++/rwww+1ceNGFS9eXGlpaWrXrp3GjRsnJycnNW/eXEuWLNGGDRuUlpam9u3by9nZmaQWyEdZTe3WrVv1/fff6/Tp0+revbvCwsK0cuVKxcTEKDg42DJ+06ZNyszM5GcWKIBIbIE8FBkZqVOnTmnNmjWWpQm///67wsLCVLhwYUty+/dkKGt/TAD5Z8WKFerVq5eaNWum2NhY/fbbb2ratKmGDRtm2Y92586d+vTTTzV//nxt2bJF1atXz+eqAdyKvYSAPJCRkSFJunHjhhISEiRJTk5OunHjhgICAvTmm2/q4MGDmjZtmnbs2CHpZkokiaYWuI8yMzNtzp07d06jRo3StGnTtHr1au3Zs0dTpkzR77//rpkzZ+rXX3/VL7/8oo8++kiHDh3Stm3baGqBAorGFrgLt/7lmNWcRkREaPv27ZoxY4YkycPDwzKmR48eOnv2rCZNmiRJrKcF7rOsf0WJiYnRhx9+qJkzZ2rbtm0qWrSokpOTVa5cOcvYiIgI9erVS998843Onz+v0qVLa+zYsVq2bJmqVq2aj58CwD9hgRCQS3/f/WDZsmU6efKkkpOT1alTJz3++OOaNGmSRo4cqeTkZD311FOSpI8++kitWrVSZGSkHnnkEe3cuVNhYWH5+TGAf5Wsn9uDBw+qQ4cOKly4sE6fPi2z2axevXopKChIN27ckCSlpqbKzc1NvXr10sSJE7Vq1SqFhYXpwQcfzOdPAeBOaGyBXMpqal966SV99tlnqlmzpry9vfXII4/o888/V9++fVWoUCH973//0zvvvCOz2ayiRYtqwIABOn78uEJCQriTGriP/t7UhoWFaciQIRo1apROnDih2bNna+PGjcrMzNSgQYO0Y8cOBQUFSbrZ4BYvXlxlypTJ3w8AIMdobIFcyNq9YOXKlVqyZIlWrVqlunXrau3atVqyZIlSUlJUtGhRDRw4UOHh4Tpy5IhcXV3VvHlzOTs7a8mSJfL19ZWfn19+fxTgXyNr+UGzZs3Upk0by3KgevXq6cKFC/rqq6+0ZMkSRUdHKywsTJMnT5aXl5d27typw4cPW/ahBlDw0dgCObBhwwY1b97csr3Pr7/+qlatWqlu3br6/PPP9cwzz+i9997Tk08+qatXr+rKlSsKCQlRSEiIJOnnn3/Wm2++qRUrVmjz5s0ktsB9lpGRoZCQEKWkpGj79u167LHHJElBQUFKTU1V4cKFtXz5cr3wwgsaO3as0tPTVaRIEX377bcKDQ3N5+oB5BQ3jwF3cOnSJQ0YMECVKlWy7GTwxx9/6NKlS/r888/17LPPasqUKRowYIAkafXq1Zo0aZISExMlSWlpabpw4YLc3Ny4mxrIJ2XKlNHixYuVmpqq1157TceOHdO1a9fUqVMn9evXT3Xq1FHhwoX1ySefaP369fruu++0YcMGy1ZfAIyBfWyBOzCbzdq5c6eee+45ubi46Mcff9TevXvVu3dvnT17VhMnTtSLL74oSUpMTNSTTz6pMmXKaObMmZadDzIyMpSWlma1SwKA++/kyZP673//q+vXr+vgwYPq3bu3pk2bJunmL6Gurq75XCGAe0FiC9yByWRS/fr19cEHHyg5OVlhYWGqW7euunTpIh8fHyUnJ+vw4cPauXOnunbtqgsXLmjatGkymUxWe9XS1AL5LzQ0VDNmzJCzs7N8fX3VqVMnyzWeJAYYH4ktkI3du3frzz//VHh4uOWGsfT0dP3444/q0aOHSpUqpW3btmncuHFas2aNDhw4oEceeUS+vr5au3atXF1deaIYUICdOnVKQ4YMkdls1tixY/Xoo4/md0kA8gCNLXCLzZs3q1mzZpJu3jX98MMPq0OHDqpVq5YefPBB7d69W88995y8vb21fft2paWlaceOHQoJCVGpUqXk5ORkaYYBFFwnT57UsGHD9Mcff2jatGmqX79+fpcE4B7R2AK3OH36tHr16qW0tDQVK1ZM5cuX18KFC1W0aFFVrlxZTZs2VeHChTVmzBhVrFhR69evt3qK2N8f4ACgYPv55581duxYvfXWWzyAAXAANLZANk6ePKlRo0YpNTVVEyZMUHBwsPbv369Zs2bp8uXL2r17t4oXL64LFy5o6NChmj59en6XDOAuZT1pDIDx0dgCt3HixAkNHTpUmZmZevXVVy2PwM3IyNBXX32ls2fPaufOnVq4cCF3UgMAUADQ2AL/4OTJkxoyZIgkafTo0WrYsGG249gmCACA/EdjC9zByZMnNXToUEnSK6+8wt3TAAAUUNzhAtxBaGioZs6cKWdnZ0VGRurgwYP5XRIAAMgGjS2QA6GhoXrjjTfUsGFDValSJb/LAQAA2WApAnAX2NILAICCh8YWAAAADoHICQAAAA6BxhYAAAAOgcYWAAAADoHGFgAAAA6BxhYAAAAOgcYWAAAADoHGFsC/WlRUlGrUqGH5uk+fPurYseN9r+PcuXMymUw6cODAbceUKVNG06dPz/Gc8+fPV+HChe+5NpPJpFWrVt3zPABgbzS2AAqcPn36yGQyyWQyydXVVQ899JBGjBihpKQku7/3jBkzNH/+/ByNzUkzCgC4f1zyuwAAyM4TTzyhefPmKS0tTd9995369eunpKQkzZ4922ZsWlqaXF1d8+R9/fz88mQeAMD9R2ILoEByd3dXYGCggoOD1bNnT0VERFj+OTxr+cBHH32khx56SO7u7jKbzbp69aoGDBigEiVKyNfXV02bNtVPP/1kNe+kSZMUEBAgHx8f9e3bVzdu3LC6futShMzMTE2ePFnlypWTu7u7HnzwQU2YMEGSFBISIkmqWbOmTCaTGjdubHndvHnzVLFiRXl4eOjhhx/Wu+++a/U+u3fvVs2aNeXh4aE6depo//79uf4eTZ06VVWrVpW3t7eCg4M1cOBAJSYm2oxbtWqVypcvLw8PD7Vo0UIxMTFW17/88kvVrl1bHh4eeuihh/Tqq68qPT091/UAQH6jsQVgCJ6enkpLS7N8ferUKX366adavny5ZSlAmzZtFBcXp6+++kr79u1TrVq11KxZM126dEmS9Omnn2r8+PGaMGGC9u7dq6CgIJuG81Yvv/yyJk+erLFjx+ro0aNasmSJAgICJN1sTiVp48aNio2N1YoVKyRJc+bM0ZgxYzRhwgQdO3ZMEydO1NixY7VgwQJJUlJSktq2basKFSpo3759ioqK0ogRI3L9PXFyctLMmTN1+PBhLViwQJs2bdLIkSOtxly/fl0TJkzQggUL9P333yshIUE9evSwXP/mm2/01FNPaejQoTp69Kjef/99zZ8/39K8A4ChmAGggOndu7e5Q4cOlq9/+OEHc9GiRc3dunUzm81m8/jx482urq7m+Ph4y5hvv/3W7Ovra75x44bVXGXLljW///77ZrPZbA4LCzM///zzVtfr1atnrl69erbvnZCQYHZ3dzfPmTMn2zrPnj1rlmTev3+/1fng4GDzkiVLrM699tpr5rCwMLPZbDa///77Zn9/f3NSUpLl+uzZs7Od6+9Kly5tnjZt2m2vf/rpp+aiRYtavp43b55ZknnXrl2Wc8eOHTNLMv/www9ms9lsfvzxx80TJ060mufjjz82BwUFWb6WZF65cuVt3xcACgrW2AIokNasWaNChQopPT1daWlp6tChg2bNmmW5Xrp0aRUvXtzy9b59+5SYmKiiRYtazZOcnKzTp09Lko4dO6bnn3/e6npYWJg2b96cbQ3Hjh1TSkqKmjVrluO6L168qJiYGPXt21f9+/e3nE9PT7es3z127JiqV68uLy8vqzpya/PmzZo4caKOHj2qhIQEpaen68aNG0pKSpK3t7ckycXFRXXq1LG85uGHH1bhwoV17NgxPfLII9q3b5/27NljldBmZGToxo0bun79ulWNAFDQ0dgCKJCaNGmi2bNny9XVVSVLlrS5OSyrccuSmZmpoKAgbdmyxWauu93yytPTM9evyczMlHRzOUK9evWsrjk7O0uSzGbzXdXzd7/88otat26t559/Xq+99pr8/f21fft29e3b12rJhnRzu65bZZ3LzMzUq6++qs6dO9uM8fDwuOc6AeB+orEFUCB5e3urXLlyOR5fq1YtxcXFycXFRWXKlMl2TMWKFbVr1y49/fTTlnO7du267ZyhoaHy9PTUt99+q379+tlcd3Nzk3Qz4cwSEBCgBx54QGfOnFFERES281aqVEkff/yxkpOTLc3zP9WRnb179yo9PV1vvfWWnJxu3i7x6aef2oxLT0/X3r179cgjj0iSjh8/ritXrujhhx+WdPP7dvz48Vx9rwGgoKKxBeAQmjdvrrCwMHXs2FGTJ09WhQoV9Ntvv+mrr75Sx44dVadOHf33v/9V7969VadOHT322GNavHixjhw5ooceeijbOT08PDRq1CiNHDlSbm5uevTRR3Xx4kUdOXJEffv2VYkSJeTp6al169apVKlS8vDwkJ+fn6KiojR06FD5+voqPDxcKSkp2rt3ry5fvqxhw4apZ8+eGjNmjPr27atXXnlF586d05tvvpmrz1u2bFmlp6dr1qxZateunb7//nu99957NuNcXV01ZMgQzZw5U66urho8eLDq169vaXTHjRuntm3bKjg4WF27dpWTk5MOHjyoQ4cO6fXXX8/9/xAAkI/YFQGAQzCZTPrqq6/UsGFDPfvssypfvrx69Oihc+fOWXYx6N69u8aNG6dRo0apdu3a+uWXX/TCCy/847xjx47V8OHDNW7cOFWsWFHdu3dXfHy8pJvrV2fOnKn3339fJUuWVIcOHSRJ/fr104cffqj58+eratWqatSokebPn2/ZHqxQoUL68ssvdfToUdWsWVNjxozR5MmTc/V5a9SooalTp2ry5MmqUqWKFi9erOjoaJtxXl5eGjVqlHr27KmwsDB5enpq6dKlluutWrXSmjVrtGHDBtWtW1f169fX1KlTVbp06VzVAwAFgcmcF4u9AAAAgHxGYgsAAACHQGMLAAAAh0BjCwAAAIdAYwsAAACHQGMLAAAAh0BjCwAAAIdAYwsAAACHQGMLAAAAh0BjCwAAAIdAYwsAAACHQGMLAAAAh/D/ANpqdD/jS8DQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resnet = torchvision.models.resnet101(pretrained=True).to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(params=densenet.parameters(),lr=0.0001)\n",
    "# # criterion = torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean').to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "# trained_model1 = train_model(densenet,criterion,optimizer,train_loader,val_loader,num_epochs=EPOCHS)\n",
    "# # Test the model\n",
    "test_loss, accuracy, precision, recall, f1, conf_matrix = test_model(trained_model1, test_loader,criterion)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\",f1)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(conf_matrix, classes=['Negative', 'Positive'], normalize=False)\n",
    "plt.show()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1: Resnet med aug\n",
    "\n",
    "![alt text](image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jaha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
